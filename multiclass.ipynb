{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ascadmin\\Desktop\\PotentialCustomersSolution\\Automation-of-Loss-Runs\\submissions\n"
     ]
    }
   ],
   "source": [
    "# Move to the folder of submissions\n",
    "%cd C:\\Users\\ascadmin\\Desktop\\PotentialCustomersSolution\\Automation-of-Loss-Runs\\submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/ascadmin/Desktop/PotentialCustomersSolution/Automation-of-Loss-Runs/submissions\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDFtoText(path_to_pdf: str):\n",
    "    '''\n",
    "    converts PDF to a string variable\n",
    "\n",
    "    input: string\n",
    "    output: string variable containing losses with labels from PDF\n",
    "    '''\n",
    "    # initiate text variable\n",
    "\n",
    "    text = \" \"\n",
    "\n",
    "    with pdfplumber.open(path_to_pdf) as pdf:\n",
    "        pages = pdf.pages\n",
    "        for page in pages:\n",
    "            new = page.extract_text()\n",
    "            print(new)\n",
    "            text += new     \n",
    "\n",
    "    # Find the index positions of 'LOSSES' and 'ADDITIONAL INFORMATION'\n",
    "    losses_index = text.find('LOSSES')\n",
    "    additional_info_index = text.find('ADDITIONAL INFORMATION')\n",
    "\n",
    "    # Find the index position of 'LARGE LOSSES'\n",
    "    large_losses_index = text.find('LARGE LOSSES')\n",
    "\n",
    "    # Slice the string to get the portions after 'LOSSES' and 'ADDITIONAL INFORMATION'\n",
    "    losses = text[losses_index + len('LOSSES'):large_losses_index] if losses_index != -1 else ''\n",
    "\n",
    "    # Slice the string to get the parts after 'LARGE LOSSES'\n",
    "    large_losses = text[large_losses_index + len('LARGE LOSSES'):additional_info_index] if large_losses_index != -1 else ''\n",
    "\n",
    "\n",
    "    print(\"LOSSES:\\n\", losses)\n",
    "    print(\"\\nLARGE LOSSES:\\n\", large_losses)  \n",
    "\n",
    "    return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A/C: Fernlea Industries, Inc. UMBRELLA LIABILITY\n",
      "R/I: Upland Capital Group June 4, 2024\n",
      "From: Brian Kohout Telephone: (630) 209-7195\n",
      "GC RENEWAL: No\n",
      "CLIENT RENEWAL: Yes\n",
      "POLICY PERIOD: June 1, 2024 To June 1, 2025\n",
      "REINSURED PERIOD: June 1, 2024 To June 1, 2025\n",
      "TYPE OF INSURANCE: Excess Liability\n",
      "COMPANY POLICY LIMIT(S): $5,000,000 Each Occurrence / $5,000,000 Aggregate Excess of\n",
      "- Any/All Underlying Insurance and/or Self-Insured Retention\n",
      "- (SIR)\n",
      "TOTAL POLICY PREMIUM: $135,000 Gross\n",
      "COMPANY RETENTION A) $100,000 Each Occurrence/$100,000 Aggregate\n",
      "Net &/Or Treaty: (Being 10.0000%) Part of $1,000,000 Each\n",
      "Occurrence/$1,000,000 Aggregate Excess Any/All\n",
      "- Underlying Insurance and/or Self-Insured\n",
      "- Retention (SIR)\n",
      "-\n",
      "B) $4,000,000 Each Occurrence/$4,000,000 Aggregate\n",
      "Excess $1,000,000 Each Occurrence/$1,000,000\n",
      "Aggregate Excess Any/All Underlying Insurance\n",
      "and/or Self-Insured Retention (SIR)\n",
      "OTHER FACULTATIVE: Placed Elsewhere by Company\n",
      "None\n",
      "REINSURANCE LIMIT(S) A) BASIS OF ACCEPTANCE: Contributing Excess\n",
      "HEREON: $900,000 Each Occurrence/$900,000 Aggregate\n",
      "(Being 90.0000%) Part of $1,000,000 Each\n",
      "Occurrence/$1,000,000 Aggregate Excess Any/All\n",
      "Underlying Insurance and/or Self-Insured\n",
      "Retention (SIR)\n",
      "REINSURANCE PREMIUM: A) $45,000 Gross less Ceding\n",
      "- Commission = $32,625 Net Annual flat\n",
      "-\n",
      "- $50,000 Gross Layer Premium\n",
      "CEDING COMMISSION: 27.50%\n",
      "ORIGINAL CANCELLATION 90 days\n",
      "CLAUSE:\n",
      "REINSURANCE CONDITIONS: Follow Form Company Policy except as stated in\n",
      "Additional Reinsurance Conditions.\n",
      "COMPANY POLICY FORM: OCCURRENCE FORM\n",
      "Loss Adjustment Expense: Outside\n",
      "U12804.245012.01 UMBRELLA LIABILITY Page 1 of 3\n",
      "A/C: Fernlea Industries, Inc. UMBRELLA LIABILITY\n",
      "R/I: Upland Capital Group June 4, 2024\n",
      "EXPOSURE BASE: Start Date End Date Sales\n",
      "Projected: 06/01/2024 06/01/2025 99,947,816\n",
      "Historical: 06/01/2023 06/01/2024 78,027,122\n",
      "06/01/2022 06/01/2023 75,873,598\n",
      "FLEET: Type Units Radius\n",
      "Light . 4 Local/Inter\n",
      "Trucks - Heavy . 2 Local/Inter\n",
      "TOTAL: 6\n",
      "Garaging: Florida\n",
      "Trailer: 1\n",
      "UNDERLYING SCHEDULE:\n",
      "Coverage Limit Company Premium Policy Term\n",
      "CGL 1M/3M/2M/1M Florist Mutual* $170,474 06/01/2024-2025\n",
      "AL 1M CSL Progressive $167,360 06/01/2024-2025\n",
      "EL 1M/1M/1M Florist Mutual* Included 06/01/2024-2025\n",
      "*Florist Mutual is on Sentry Paper\n",
      "GL forms of note: Exclusions: Cyber, Professional, CD, A&B, Fungi/Bacteria,\n",
      "Construction Defect(?), Misdelivery, EL, Oil or Gas producing ops,\n",
      "Other: Per project agg $5m, Warranty of Sub limits (min 1/2/2/1), WOS. PNC\n",
      "wording.\n",
      "Upland Policy Includes: Service of Suit, Cap On Losses From Certified Acts\n",
      "Of Terrorism, Unimpaired Aggregate Limit\n",
      "Our Exclusions:, Access or Disclosure of Confidential or Personal\n",
      "Information, Lead, Asbestos, Biometric Info, CCC, CD, Cross Suits, Cyber,\n",
      "ERP, ERISA, EIFS , Fungi/Bacteria, MCS-90, Professional Services, Silica,\n",
      "Unmanned Aircraft, Wrongful Delivery of Liquid Products, Employee Benefit\n",
      "Plan, Nuclear, Total Pollution with Hostile Fire, TRIA, Coverage Territory\n",
      "Limitation.\n",
      "LOSSES: Valuation Date: 05/07/2024\n",
      "Gen'l Liab Auto Liab Excess Auto Liab\n",
      "TOTAL TOTAL TOTAL\n",
      "YEAR INCURRED NUMBER INCURRED NUMBER INCURRED NUMBER\n",
      "06/01/2023-06/01/2024 $5 2 0 $0 0\n",
      "06/01/2022-06/01/2023 $44,574 2 0 $0 0\n",
      "06/01/2021-06/01/2022 $2,245 4 $21,845 10 $0 0\n",
      "06/01/2020-06/01/2021 $3,298 7 $1,094,083 4 $1,762,338 1\n",
      "06/01/2019-06/01/2020 $4,826 4 $2,681 5 $0 0\n",
      "06/01/2018-06/01/2019 $106,121 7 $26,007 5 $0 0\n",
      "LARGE LOSSES: Valuation Date: 05/07/2024A\n",
      "Total Line\n",
      "DOL Incurred O/C Paid Reserve Type Description\n",
      "03/29/2021 2,846,123 C 2,846,123 0 UL Insured vehicle backing\n",
      "up to claimant's\n",
      "receiving dock doors and\n",
      "insured backed too far\n",
      "and struck the claimant's\n",
      "building. Bricks\n",
      "shattered and came into\n",
      "the building and the roll\n",
      "up door frame is damaged.\n",
      "U12804.245012.01 UMBRELLA LIABILITY Page 2 of 3\n",
      "A/C: Fernlea Industries, Inc. UMBRELLA LIABILITY\n",
      "R/I: Upland Capital Group June 4, 2024\n",
      "LARGE LOSSES (continued)\n",
      "Total Line\n",
      "DOL Incurred O/C Paid Reserve Type Description\n",
      "Over 50% at fault.\n",
      "ADDITIONAL INFORMATION:\n",
      "Sales by State:\n",
      "-FL: 95,623,901\n",
      "-CA: 4,323,915\n",
      "U12804.245012.01 UMBRELLA LIABILITY Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "fernlea = PDFtoText(\"Fernlea.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_count(text:str):\n",
    "    '''\n",
    "    Determines how many classes there are in the text.\n",
    "    There are 4 classes in total: Gen'l Liab, Auto liab, Excess Auto Liab, and Professional Liab\n",
    "\n",
    "    input: \n",
    "    string that contains the labels extracted from pdf\n",
    "\n",
    "    outputs: \n",
    "    - count of how many unique claases there are (int)\n",
    "    - names of the unique classes (list of strings)\n",
    "    '''\n",
    "    # Regular expression to find patterns that look like the labels\n",
    "    # We assume labels consist of one or two words ending with 'Liab' \n",
    "    # -> if there are new classes, change the following line of code\n",
    "    pattern = re.compile(r\"(Gen'l Liab|Auto Liab|Excess Auto Liab|Professional Liab)\")\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = pattern.findall(text)\n",
    "    \n",
    "    # Convert list of matches to a set to remove duplicates\n",
    "    unique_labels = set(matches)\n",
    "    \n",
    "    # Return the count of unique labels and the list of unique labels\n",
    "    return len(unique_labels), list(unique_labels)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSSES:\n",
      " : Valuation Date: 05/07/2024\n",
      "Gen'l Liab Auto Liab Excess Auto Liab\n",
      "TOTAL TOTAL TOTAL\n",
      "YEAR INCURRED NUMBER INCURRED NUMBER INCURRED NUMBER\n",
      "06/01/2023-06/01/2024 $5 2 0 $0 0\n",
      "06/01/2022-06/01/2023 $44,574 2 0 $0 0\n",
      "06/01/2021-06/01/2022 $2,245 4 $21,845 10 $0 0\n",
      "06/01/2020-06/01/2021 $3,298 7 $1,094,083 4 $1,762,338 1\n",
      "06/01/2019-06/01/2020 $4,826 4 $2,681 5 $0 0\n",
      "06/01/2018-06/01/2019 $106,121 7 $26,007 5 $0 0\n",
      "\n",
      "\n",
      "LARGE LOSSES:\n",
      " : Valuation Date: 05/07/2024A\n",
      "Total Line\n",
      "DOL Incurred O/C Paid Reserve Type Description\n",
      "03/29/2021 2,846,123 C 2,846,123 0 UL Insured vehicle backing\n",
      "up to claimant's\n",
      "receiving dock doors and\n",
      "insured backed too far\n",
      "and struck the claimant's\n",
      "building. Bricks\n",
      "shattered and came into\n",
      "the building and the roll\n",
      "up door frame is damaged.\n",
      "U12804.245012.01 UMBRELLA LIABILITY Page 2 of 3A/C: Fernlea Industries, Inc. UMBRELLA LIABILITY\n",
      "R/I: Upland Capital Group June 4, 2024\n",
      "LARGE LOSSES (continued)\n",
      "Total Line\n",
      "DOL Incurred O/C Paid Reserve Type Description\n",
      "Over 50% at fault.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the index positions of 'LOSSES' and 'ADDITIONAL INFORMATION'\n",
    "losses_index = fernlea.find('LOSSES')\n",
    "additional_info_index = fernlea.find('ADDITIONAL INFORMATION')\n",
    "\n",
    "# Find the index position of 'LARGE LOSSES'\n",
    "large_losses_index = fernlea.find('LARGE LOSSES')\n",
    "\n",
    "# Slice the string to get the portions after 'LOSSES' and 'ADDITIONAL INFORMATION'\n",
    "losses = fernlea[losses_index + len('LOSSES'):large_losses_index] if losses_index != -1 else ''\n",
    "\n",
    "# Slice the string to get the parts after 'LARGE LOSSES'\n",
    "large_losses = fernlea[large_losses_index + len('LARGE LOSSES'):additional_info_index] if large_losses_index != -1 else ''\n",
    "\n",
    "\n",
    "print(\"LOSSES:\\n\", losses)\n",
    "print(\"\\nLARGE LOSSES:\\n\", large_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first 4 rows of losses\n",
    "# Split the text into lines\n",
    "lines = losses.strip().split('\\n')\n",
    "\n",
    "# Remove the first four lines\n",
    "lines = lines[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, lst = multiclass_count(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ['Excess Auto Liab', 'Auto Liab', \"Gen'l Liab\"]\n"
     ]
    }
   ],
   "source": [
    "print(count,lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish implementing ExportDf\n",
    "\n",
    "def ExportDf(text):\n",
    "    '''\n",
    "    Process the text string when there is more than one class.\n",
    "    There are 4 classes in total: Gen'l Liab, Auto liab, Excess Auto Liab, and Professional Liab\n",
    "    input: string that contains the text extracted from pdf\n",
    "    output: standardized pandas dataframe\n",
    "    '''\n",
    "\n",
    "    count, lst = multiclass_count(text) \n",
    "\n",
    "    # define number of columns\n",
    "    # the formula is 2 (start date and end date) + count * 2 (rach class has 2 columns, total incurred and total number)\n",
    "\n",
    "    # Define the number of columns based on the formula\n",
    "    num_columns = 2 * count + 2\n",
    "\n",
    "    # Create a DataFrame with the required number of columns\n",
    "    column_names = []\n",
    "    for label in lst:\n",
    "        column_names.extend([f\"{label} Total Incurred\", f\"{label} Total Number\"])\n",
    "    column_names.extend([\"Effective Date\", \"Expiration Date\", \"Evaluation Date\"])\n",
    "\n",
    "    # Initialize the DataFrame with zero rows, just column definitions\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    print(df)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish implementing mtach_round1\n",
    "\n",
    "def match_round1(num_classes:str ):\n",
    "    '''\n",
    "    Goes through all lines\n",
    "    in the variables \"lines\" (losses without headers) and attemtps \n",
    "    to match each line to the default pattern. \n",
    "\n",
    "    inputs:\n",
    "\n",
    "    outputs:\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Matches:\n",
      "('06/01/2021-06/01/2022', '$2,245', '4', '$21,845', '10', '$0', '0')\n",
      "('06/01/2020-06/01/2021', '$3,298', '7', '$1,094,083', '4', '$1,762,338', '1')\n",
      "('06/01/2019-06/01/2020', '$4,826', '4', '$2,681', '5', '$0', '0')\n",
      "('06/01/2018-06/01/2019', '$106,121', '7', '$26,007', '5', '$0', '0')\n"
     ]
    }
   ],
   "source": [
    "# First round: Extracting data from the text\n",
    "data_pattern = re.compile(r\"(\\d{2}/\\d{2}/\\d{4}-\\d{2}/\\d{2}/\\d{4}) ([\\$\\d,]+|\\$0|\\$\\d|\\S*) (\\d+|\\d|0) ([\\$\\d,]+|\\$0|\\$\\d|0|\\S*) (\\d+|\\d|0) ([\\$\\d,]+|\\$0|\\$\\d|0|\\S*) (\\d+|\\d|0)\")\n",
    "\n",
    "# if there are rows that are not captured, include them\n",
    "# assuming that the total incurred could be missing\n",
    "\n",
    "# find matches\n",
    "matches = data_pattern.findall(losses)\n",
    "\n",
    "# check if any expected data is missing\n",
    "if not matches:\n",
    "    print(\"No data captured. Please check the losses string format.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Captured Matches:\")\n",
    "    for match in matches:\n",
    "        print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\": Valuation Date: 05/07/2024\\nGen'l Liab Auto Liab Excess Auto Liab\\nTOTAL TOTAL TOTAL\\nYEAR INCURRED NUMBER INCURRED NUMBER INCURRED NUMBER\\n06/01/2023-06/01/2024 $5 2 0 $0 0\\n06/01/2022-06/01/2023 $44,574 2 0 $0 0\\n06/01/2021-06/01/2022 $2,245 4 $21,845 10 $0 0\\n06/01/2020-06/01/2021 $3,298 7 $1,094,083 4 $1,762,338 1\\n06/01/2019-06/01/2020 $4,826 4 $2,681 5 $0 0\\n06/01/2018-06/01/2019 $106,121 7 $26,007 5 $0 0\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06/01/2023-06/01/2024 $5 2 0 $0 0', '06/01/2022-06/01/2023 $44,574 2 0 $0 0', '06/01/2021-06/01/2022 $2,245 4 $21,845 10 $0 0', '06/01/2020-06/01/2021 $3,298 7 $1,094,083 4 $1,762,338 1', '06/01/2019-06/01/2020 $4,826 4 $2,681 5 $0 0', '06/01/2018-06/01/2019 $106,121 7 $26,007 5 $0 0']\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(line, pattern:re.Pattern, matches:list, pattern_ind:int, line_ind:int):\n",
    "    '''\n",
    "    This function takes in a unmatched line in round 1 (due to missing values)\n",
    "    and reformats it so that\n",
    "    (1) It's in the standarized format\n",
    "    (2) missing value defaults to 0\n",
    "    (3) Adds the reformatted line to the list named \"matches\"\n",
    "\n",
    "    inputs: \n",
    "    - line (str): a line from the list \"unmatched\". Lines contains all lines in the loss run table \n",
    "    - pattern (re.Pattern): the pattern that the unmatched line matched to in the 2nd round\n",
    "    - matches (list): the list that contains all lines that matched with the default pattern from the 1st round. Example:\n",
    "        ('06/01/2021-06/01/2022', '$2,245', '4', '$21,845', '10', '$0', '0')\n",
    "        ('06/01/2020-06/01/2021', '$3,298', '7', '$1,094,083', '4', '$1,762,338', '1')\n",
    "        ('06/01/2019-06/01/2020', '$4,826', '4', '$2,681', '5', '$0', '0')\n",
    "        ('06/01/2018-06/01/2019', '$106,121', '7', '$26,007', '5', '$0', '0')`\n",
    "    - pattern_ind (int): the index of the pattern\n",
    "\n",
    "    output:\n",
    "    - matches (list): OG list with reformatted matches appended\n",
    "    '''\n",
    "\n",
    "    match = pattern.search(line)\n",
    "    print(f\"match is {match}\")\n",
    "    \n",
    "    # Extract the groups from the match\n",
    "    groups = list(match.groups())\n",
    "\n",
    "    print(f\"Current unmatched line number is {line_ind}.\")\n",
    "    print(f\"Current unmatched line is {line}.\")\n",
    "\n",
    "    # Extract the groups from the match, check is matach is none\n",
    "    groups = list(match.groups())    \n",
    "    \n",
    "    # Replace empty values with '0'\n",
    "    # since we know the 2nd incurred is missing, \n",
    "    # add $0 in the position where the second total incurred value should be\n",
    "    standardized_groups = groups.copy()\n",
    "\n",
    "    # two ways to do this\n",
    "    # (1) insert  without checking (faster)\n",
    "    # check that the index 3 is 0 \n",
    "    # insert \"$0\" at index 3\n",
    "    if (standardized_groups[pattern_ind + 1] == '0'):\n",
    "        standardized_groups.insert(pattern_ind+1, \"$0\")\n",
    "    else: \n",
    "        print(\"The 2nd number of claims is not 0!\")\n",
    "\n",
    "    # (2) check for 0 as claims value (we are not using this yet, wait til testing)\n",
    "    # for index, g in enumerate(groups):\n",
    "    #     if index == 3 and g.strip() == '0':  # Check if the position corresponds to the second incurred\n",
    "    #         standardized_groups.append('$0')  # Insert '$0' for the missing second incurred value\n",
    "    #     else:\n",
    "    #         standardized_groups.append(g if g and g.strip() != '$0' else '0')  # Handle other values as usual\n",
    "            \n",
    "    # Insert the standardized tuple to the right position in matches\n",
    "    # use the index, line[0]\n",
    "    matches.insert(line_ind-1, tuple(standardized_groups))\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '06/01/2023-06/01/2024 $5 2 0 $0 0'),\n",
       " (2, '06/01/2022-06/01/2023 $44,574 2 0 $0 0')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows are successfully captured after second check.\n"
     ]
    }
   ],
   "source": [
    "# 2nd Round: check if there are rows that might not be captured by analyzing the text more closely\n",
    "\n",
    "# remove first 4 rows of losses\n",
    "# Split the text into lines\n",
    "lines = losses.strip().split('\\n')\n",
    "\n",
    "# Remove the first four lines\n",
    "lines = lines[4:]\n",
    "\n",
    "expected_rows = len(lines) \n",
    "\n",
    "if len(matches) != expected_rows:\n",
    "    print(f\"Expected to capture {expected_rows} rows, but only captured {len(matches)}.\")\n",
    "    missing_rows_count = expected_rows - len(matches)\n",
    "    print(f\"Missing rows count: {missing_rows_count}\")\n",
    "\n",
    "    # track lines that weren't captured\n",
    "    unmatched = []\n",
    "\n",
    "    # Analyze each line, add all unmatched lines in the 1st round\n",
    "    for index, line in enumerate(lines):\n",
    "        if not data_pattern.search(line):\n",
    "            unmatched.append((index, line))  # Add 1 to index because line numbers usually start at 1\n",
    "\n",
    "    print(unmatched)\n",
    "\n",
    "    # Try alternative patterns to capture these lines, ADD DIFFERENT PATTERNS IF NEEDED\n",
    "    for line_number, line in unmatched:\n",
    "        # Pattern with the first incurred loss possibly missing\n",
    "        pattern1 = re.compile(r\"(\\d{2}/\\d{2}/\\d{4}-\\d{2}/\\d{2}/\\d{4}) (\\d+|0) ([\\$\\d,]+|\\$0|\\$\\d|0|\\S*) (\\d+|0) ([\\$\\d,]+|\\$0|\\$\\d|0|\\S*) (\\d+|0)\")\n",
    "\n",
    "        # Pattern with the second incurred loss possibly missing\n",
    "        pattern2 = re.compile(r\"(\\d{2}/\\d{2}/\\d{4}-\\d{2}/\\d{2}/\\d{4}) ([\\$\\d,]+|\\$0|\\$\\d|\\S*) (\\d+|0) (\\d+|0) ([\\$\\d,]+|\\$0|\\$\\d|0|\\S*) (\\d+|0)\")\n",
    "            \n",
    "        # Pattern with the third incurred loss possibly missing\n",
    "        pattern3 = re.compile(r\"(\\d{2}/\\d{2}/\\d{4}-\\d{2}/\\d{2}/\\d{4}) ([\\$\\d,]+|\\$0|\\$\\d|\\S*) (\\d+|0) ([\\$\\d,]+|\\$0|\\$\\d|0|\\S*) (\\d+|0) (\\d+|0)\")\n",
    "\n",
    "        if pattern1.search(line):\n",
    "            print(f\"Line {line_number} matches pattern1.\")\n",
    "\n",
    "            # call reformat to reformat this line\n",
    "            reformat(line, pattern1, matches, 1, line_number)\n",
    "            \n",
    "        elif pattern2.search(line):\n",
    "            print(f\"Line {line_number} matches pattern2.\")\n",
    "\n",
    "            reformat(line, pattern2, matches, 2, line_number)\n",
    "\n",
    "        elif pattern3.search(line):\n",
    "            print(f\"Line {line_number} matches pattern3.\")\n",
    "\n",
    "            reformat(line, pattern3, matches, 3, line_number)\n",
    "        else:\n",
    "            print(f\"Line {line_number} does not match any known pattern.\")\n",
    "    else:\n",
    "        print(\"All lines are successfully captured after second check.\")\n",
    "    \n",
    "else:\n",
    "    print(\"All rows are successfully captured after second check.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('06/01/2021-06/01/2022', '$2,245', '4', '$21,845', '10', '$0', '0'),\n",
       " ('06/01/2023-06/01/2024', '$5', '2', '$0', '0', '$0', '0'),\n",
       " ('06/01/2022-06/01/2023', '$44,574', '2', '$0', '0', '$0', '0'),\n",
       " ('06/01/2020-06/01/2021',\n",
       "  '$3,298',\n",
       "  '7',\n",
       "  '$1,094,083',\n",
       "  '4',\n",
       "  '$1,762,338',\n",
       "  '1'),\n",
       " ('06/01/2019-06/01/2020', '$4,826', '4', '$2,681', '5', '$0', '0'),\n",
       " ('06/01/2018-06/01/2019', '$106,121', '7', '$26,007', '5', '$0', '0')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches\n",
    "\n",
    "# organize by start date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('06/01/2021-06/01/2022', '$2,245', '4', '$21,845', '10', '$0', '0')\n",
      "('06/01/2023-06/01/2024', '$5', '2', '$0', '0', '$0', '0')\n",
      "('06/01/2022-06/01/2023', '$44,574', '2', '$0', '0', '$0', '0')\n",
      "('06/01/2020-06/01/2021', '$3,298', '7', '$1,094,083', '4', '$1,762,338', '1')\n",
      "('06/01/2019-06/01/2020', '$4,826', '4', '$2,681', '5', '$0', '0')\n",
      "('06/01/2018-06/01/2019', '$106,121', '7', '$26,007', '5', '$0', '0')\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Gen'l Liab Total Incurred\": '$2,245', \"Gen'l Liab Number\": '4', 'Auto Liab Total Incurred': '$21,845', 'Auto Liab Number': '10', 'Excess Auto Liab Total Incurred': '$0', 'Excess Auto Liab Number': '0', 'Effective Date': '06/01/2021', 'Expiration Date': '06/01/2022', 'Evaluation Date': '05/07/2024'}\n",
      "{\"Gen'l Liab Total Incurred\": '$5', \"Gen'l Liab Number\": '2', 'Auto Liab Total Incurred': '$0', 'Auto Liab Number': '0', 'Excess Auto Liab Total Incurred': '$0', 'Excess Auto Liab Number': '0', 'Effective Date': '06/01/2023', 'Expiration Date': '06/01/2024', 'Evaluation Date': '05/07/2024'}\n",
      "{\"Gen'l Liab Total Incurred\": '$44,574', \"Gen'l Liab Number\": '2', 'Auto Liab Total Incurred': '$0', 'Auto Liab Number': '0', 'Excess Auto Liab Total Incurred': '$0', 'Excess Auto Liab Number': '0', 'Effective Date': '06/01/2022', 'Expiration Date': '06/01/2023', 'Evaluation Date': '05/07/2024'}\n",
      "{\"Gen'l Liab Total Incurred\": '$3,298', \"Gen'l Liab Number\": '7', 'Auto Liab Total Incurred': '$1,094,083', 'Auto Liab Number': '4', 'Excess Auto Liab Total Incurred': '$1,762,338', 'Excess Auto Liab Number': '1', 'Effective Date': '06/01/2020', 'Expiration Date': '06/01/2021', 'Evaluation Date': '05/07/2024'}\n",
      "{\"Gen'l Liab Total Incurred\": '$4,826', \"Gen'l Liab Number\": '4', 'Auto Liab Total Incurred': '$2,681', 'Auto Liab Number': '5', 'Excess Auto Liab Total Incurred': '$0', 'Excess Auto Liab Number': '0', 'Effective Date': '06/01/2019', 'Expiration Date': '06/01/2020', 'Evaluation Date': '05/07/2024'}\n",
      "{\"Gen'l Liab Total Incurred\": '$106,121', \"Gen'l Liab Number\": '7', 'Auto Liab Total Incurred': '$26,007', 'Auto Liab Number': '5', 'Excess Auto Liab Total Incurred': '$0', 'Excess Auto Liab Number': '0', 'Effective Date': '06/01/2018', 'Expiration Date': '06/01/2019', 'Evaluation Date': '05/07/2024'}\n",
      "  Gen'l Liab Total Incurred Gen'l Liab Number Auto Liab Total Incurred  \\\n",
      "0                    $2,245                 4                  $21,845   \n",
      "1                        $5                 2                       $0   \n",
      "2                   $44,574                 2                       $0   \n",
      "3                    $3,298                 7               $1,094,083   \n",
      "4                    $4,826                 4                   $2,681   \n",
      "5                  $106,121                 7                  $26,007   \n",
      "\n",
      "  Auto Liab Number Excess Auto Liab Total Incurred Excess Auto Liab Number  \\\n",
      "0               10                              $0                       0   \n",
      "1                0                              $0                       0   \n",
      "2                0                              $0                       0   \n",
      "3                4                      $1,762,338                       1   \n",
      "4                5                              $0                       0   \n",
      "5                5                              $0                       0   \n",
      "\n",
      "  Effective Date Expiration Date Evaluation Date  \n",
      "0     06/01/2021      06/01/2022      05/07/2024  \n",
      "1     06/01/2023      06/01/2024      05/07/2024  \n",
      "2     06/01/2022      06/01/2023      05/07/2024  \n",
      "3     06/01/2020      06/01/2021      05/07/2024  \n",
      "4     06/01/2019      06/01/2020      05/07/2024  \n",
      "5     06/01/2018      06/01/2019      05/07/2024  \n"
     ]
    }
   ],
   "source": [
    "# List to hold each row's data (as dictionaries)\n",
    "rows = []\n",
    "\n",
    "# Process each match to create a dictionary for each row\n",
    "for match in matches:\n",
    "    date_range, gl_incurred, gl_number, al_incurred, al_number, eal_incurred, eal_number = match\n",
    "    start_date, end_date = date_range.split('-')\n",
    "    row = {\n",
    "        'Gen\\'l Liab Total Incurred': gl_incurred,\n",
    "        'Gen\\'l Liab Number': gl_number,\n",
    "        'Auto Liab Total Incurred': al_incurred,\n",
    "        'Auto Liab Number': al_number,\n",
    "        'Excess Auto Liab Total Incurred': eal_incurred,\n",
    "        'Excess Auto Liab Number': eal_number,\n",
    "        'Effective Date': start_date,\n",
    "        'Expiration Date': end_date,\n",
    "        'Evaluation Date': '05/07/2024'  # TODO: This should be taken from the text\n",
    "    }\n",
    "    print(row)\n",
    "    rows.append(row)\n",
    "\n",
    "# Define the column names based on the labels found\n",
    "column_names = [\n",
    "    'Gen\\'l Liab Total Incurred', 'Gen\\'l Liab Number',\n",
    "    'Auto Liab Total Incurred', 'Auto Liab Number',\n",
    "    'Excess Auto Liab Total Incurred', 'Excess Auto Liab Number',\n",
    "    'Effective Date', 'Expiration Date', 'Evaluation Date'\n",
    "]\n",
    "\n",
    "# Initialize the DataFrame with the row data\n",
    "df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
